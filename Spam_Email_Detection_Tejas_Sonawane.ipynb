{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "af4eb57a-9dbf-4c0f-8e7d-a484aa6de6f9",
   "metadata": {},
   "source": [
    "Problem Statement:\n",
    "\n",
    "We've all been the recipient of spam emails before. Spam mail, or junk mail, is a type of email that is sent to a massive number of users at one time, frequently containing cryptic messages, scams, or most dangerously, phishing content.\r\n",
    "\r\n",
    "\r\n",
    "In this Project, use Python to build an email spam detector. Then, use machine learning to train the spam detector to recognize and classify emails into spam and non-spam. Lets get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "995ffc76-2590-4ec0-a21e-cded7c8a9445",
   "metadata": {},
   "source": [
    "1. Collecting data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4598ef1-fb8a-4418-8c44-80f344379b08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     v1                                                 v2 Unnamed: 2  \\\n",
      "0   ham  Go until jurong point, crazy.. Available only ...        NaN   \n",
      "1   ham                      Ok lar... Joking wif u oni...        NaN   \n",
      "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...        NaN   \n",
      "3   ham  U dun say so early hor... U c already then say...        NaN   \n",
      "4   ham  Nah I don't think he goes to usf, he lives aro...        NaN   \n",
      "5  spam  FreeMsg Hey there darling it's been 3 week's n...        NaN   \n",
      "6   ham  Even my brother is not like to speak with me. ...        NaN   \n",
      "7   ham  As per your request 'Melle Melle (Oru Minnamin...        NaN   \n",
      "8  spam  WINNER!! As a valued network customer you have...        NaN   \n",
      "9  spam  Had your mobile 11 months or more? U R entitle...        NaN   \n",
      "\n",
      "  Unnamed: 3 Unnamed: 4  \n",
      "0        NaN        NaN  \n",
      "1        NaN        NaN  \n",
      "2        NaN        NaN  \n",
      "3        NaN        NaN  \n",
      "4        NaN        NaN  \n",
      "5        NaN        NaN  \n",
      "6        NaN        NaN  \n",
      "7        NaN        NaN  \n",
      "8        NaN        NaN  \n",
      "9        NaN        NaN  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "data = pd.read_csv(\"C:\\\\Users\\\\King\\\\Desktop\\\\Cipherbyte Internship\\\\Spam Email Detection - spam.csv\")\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "print(data.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0de9fb4b-9bed-48d2-a0a0-6080a0358867",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  label                                               text\n",
      "0   ham  Go until jurong point, crazy.. Available only ...\n",
      "1   ham                      Ok lar... Joking wif u oni...\n",
      "2  spam  Free entry in 2 a wkly comp to win FA Cup fina...\n",
      "3   ham  U dun say so early hor... U c already then say...\n",
      "4   ham  Nah I don't think he goes to usf, he lives aro...\n",
      "5  spam  FreeMsg Hey there darling it's been 3 week's n...\n",
      "6   ham  Even my brother is not like to speak with me. ...\n",
      "7   ham  As per your request 'Melle Melle (Oru Minnamin...\n",
      "8  spam  WINNER!! As a valued network customer you have...\n",
      "9  spam  Had your mobile 11 months or more? U R entitle...\n"
     ]
    }
   ],
   "source": [
    "# Keeping only relevant columns and rename them\n",
    "data = data[['v1', 'v2']]\n",
    "data.columns = ['label', 'text']\n",
    "\n",
    "# Display the first few rows of the dataset\n",
    "print(data.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b710087a-054e-439d-b61a-dad089240793",
   "metadata": {},
   "source": [
    "2. Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7c83d77a-2eab-46ea-96f3-5f49667d553e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    go until jurong point crazy available only in ...\n",
      "1                              ok lar joking wif u oni\n",
      "2    free entry in 2 a wkly comp to win fa cup fina...\n",
      "3          u dun say so early hor u c already then say\n",
      "4    nah i dont think he goes to usf he lives aroun...\n",
      "5    freemsg hey there darling its been 3 weeks now...\n",
      "6    even my brother is not like to speak with me t...\n",
      "7    as per your request melle melle oru minnaminun...\n",
      "8    winner as a valued network customer you have b...\n",
      "9    had your mobile 11 months or more u r entitled...\n",
      "Name: clean_text, dtype: object\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Remove HTML tags\n",
    "    text = re.sub(r'<[^>]+>', '', text)\n",
    "    # Remove special characters and punctuation\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    # Convert text to lowercase\n",
    "    text = text.lower()\n",
    "    return text\n",
    "\n",
    "# Apply preprocessing to the 'text' column\n",
    "data['clean_text'] = data['text'].apply(preprocess_text)\n",
    "\n",
    "# Display the first few rows of the preprocessed text\n",
    "print(data['clean_text'].head(10))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02c1a063-a4cf-4331-9405-22f67eb43ab2",
   "metadata": {},
   "source": [
    "3. Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "44c7a6da-8674-4bc6-a318-049b60b52266",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF Matrix Shape: (5572, 9442)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Initializing the TF-IDF vectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Fit and transform the clean text data\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(data['clean_text'])\n",
    "\n",
    "# Display the shape of the TF-IDF matrix\n",
    "print(\"TF-IDF Matrix Shape:\", tfidf_matrix.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ba33a05-a827-4671-8b5a-42201dc5fb0d",
   "metadata": {},
   "source": [
    "4. Model building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4045c0ed-bdc5-4154-a14e-3e0c701ca0d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(tfidf_matrix, data['label'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Initializing the Naive Bayes classifier\n",
    "nb_classifier = MultinomialNB()\n",
    "\n",
    "# Training the classifier\n",
    "nb_classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the testing set\n",
    "y_pred = nb_classifier.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce1e68e3-b5c6-4a2b-912c-a1a7dc851a0e",
   "metadata": {},
   "source": [
    "5. Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "08c817ea-619b-46ff-8ef2-d2b7e0182f2e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.95695067264574\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.95      1.00      0.98       965\n",
      "        spam       1.00      0.68      0.81       150\n",
      "\n",
      "    accuracy                           0.96      1115\n",
      "   macro avg       0.98      0.84      0.89      1115\n",
      "weighted avg       0.96      0.96      0.95      1115\n",
      "\n",
      "Confusion Matrix:\n",
      "[[965   0]\n",
      " [ 48 102]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "\n",
    "# Calculating accuracy\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "# Classification report\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Confusion matrix\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c2b919f5-4ae4-4806-a33e-a0fcdeb476fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['ham', 'ham', 'ham', ..., 'ham', 'ham', 'ham'], dtype=object)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example: Random Forest classifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_classifier.fit(X_train, y_train)\n",
    "rf_classifier\n",
    "y_pred_rf = rf_classifier.predict(X_test)\n",
    "y_pred_rf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0398188e-e379-41c7-883b-331ad9f2406f",
   "metadata": {},
   "source": [
    "6. Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fc817196-b25c-4ea6-bea1-b09ffef63c68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'alpha': 0.1}\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>MultinomialNB(alpha=0.1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MultinomialNB</label><div class=\"sk-toggleable__content\"><pre>MultinomialNB(alpha=0.1)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "MultinomialNB(alpha=0.1)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Define the parameter grid\n",
    "param_grid = {'alpha': [0.1, 0.5, 1.0, 2.0]}\n",
    "\n",
    "# Initialize the Naive Bayes classifier\n",
    "nb_classifier = MultinomialNB()\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search = GridSearchCV(nb_classifier, param_grid, cv=5, scoring='accuracy')\n",
    "\n",
    "# Perform grid search\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Get the best hyperparameters\n",
    "best_params = grid_search.best_params_\n",
    "print(\"Best Hyperparameters:\", best_params)\n",
    "\n",
    "# Train the classifier with the best hyperparameters\n",
    "best_nb_classifier = MultinomialNB(alpha=best_params['alpha'])\n",
    "best_nb_classifier.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b9ae86b4-1334-4c5c-bd69-5786c7217fb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Accuracy: 0.9944364680545585\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.99      1.00      1.00      4825\n",
      "        spam       0.99      0.97      0.98       747\n",
      "\n",
      "    accuracy                           0.99      5572\n",
      "   macro avg       0.99      0.98      0.99      5572\n",
      "weighted avg       0.99      0.99      0.99      5572\n",
      "\n",
      "Confusion Matrix:\n",
      "[[4820    5]\n",
      " [  26  721]]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on the entire dataset\n",
    "y_pred_all = best_nb_classifier.predict(tfidf_matrix)\n",
    "\n",
    "# Calculate overall accuracy\n",
    "accuracy_all = accuracy_score(data['label'], y_pred_all)\n",
    "print(\"Overall Accuracy:\", accuracy_all)\n",
    "\n",
    "# Print classification report and confusion matrix for the entire dataset\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(data['label'], y_pred_all))\n",
    "\n",
    "print(\"Confusion Matrix:\")\n",
    "print(confusion_matrix(data['label'], y_pred_all))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9578f7b7-ad3c-477b-b6fa-329e6e522018",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 Spam Words:\n",
      "to\n",
      "call\n",
      "free\n",
      "your\n",
      "you\n",
      "or\n",
      "now\n",
      "txt\n",
      "for\n",
      "mobile\n",
      "\n",
      "Top 10 Ham Words:\n",
      "you\n",
      "to\n",
      "the\n",
      "me\n",
      "in\n",
      "my\n",
      "and\n",
      "is\n",
      "ok\n",
      "it\n"
     ]
    }
   ],
   "source": [
    "# Get the most informative words for each class\n",
    "feature_names = tfidf_vectorizer.get_feature_names_out()\n",
    "top_spam_words = sorted(zip(best_nb_classifier.feature_log_prob_[1], feature_names), reverse=True)[:10]\n",
    "top_ham_words = sorted(zip(best_nb_classifier.feature_log_prob_[0], feature_names), reverse=True)[:10]\n",
    "\n",
    "print(\"Top 10 Spam Words:\")\n",
    "for coef, word in top_spam_words:\n",
    "    print(word)\n",
    "\n",
    "print(\"\\nTop 10 Ham Words:\")\n",
    "for coef, word in top_ham_words:\n",
    "    print(word)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "848141eb-8c11-4550-ad91-59987b7e3a58",
   "metadata": {},
   "source": [
    "7. Deployment of a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cd7590d5-bf6c-4c0a-81c0-646e662433e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted Label for the New Email: ham\n"
     ]
    }
   ],
   "source": [
    "new_email = \"Congratulations! You have done the spam email detection sucessfully.\"\n",
    "\n",
    "# Preprocess the new email\n",
    "clean_new_email = preprocess_text(new_email)\n",
    "\n",
    "# Transform the preprocessed email using the TF-IDF vectorizer\n",
    "tfidf_new_email = tfidf_vectorizer.transform([clean_new_email])\n",
    "\n",
    "# Predict the label of the new email\n",
    "predicted_label = best_nb_classifier.predict(tfidf_new_email)\n",
    "\n",
    "print(\"Predicted Label for the New Email:\", predicted_label[0])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
